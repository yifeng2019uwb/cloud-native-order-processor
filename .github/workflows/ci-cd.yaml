name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: '3.11'
  AWS_REGION: 'us-west-2'
  ECR_REPOSITORY: 'order-processor-api' # This is the Docker image name, not the full ECR URI yet

jobs:
  # Job 1: Run Tests
  test:
    name: Run Tests
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('services/*/requirements*.txt', 'services/common/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install build tools
      run: |
        python -m pip install --upgrade pip setuptools wheel build

    - name: Make build script executable
      working-directory: ./services
      run: chmod +x build.sh

    - name: Install dependencies and run tests for common package
      working-directory: ./services
      run: |
        echo "=== Building and testing common package ==="
        ./build.sh --clean --verbose common

    - name: Install dependencies and run tests for order-service
      working-directory: ./services
      run: |
        echo "=== Building and testing order-service ==="
        ./build.sh --clean --verbose order-service

    - name: Run all tests with coverage
      working-directory: ./services
      run: |
        echo "=== Running comprehensive test suite ==="
        ./build.sh --all-tests --clean --verbose --coverage 70

    - name: Build all service packages
      working-directory: ./services
      run: |
        echo "=== Building all service packages ==="
        make build-all

    - name: Upload test coverage reports
      uses: actions/upload-artifact@v4
      with:
        name: coverage-reports
        path: services/htmlcov/
        retention-days: 7

    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: build-artifacts
        path: |
          services/*/dist/
          services/common/dist/
        retention-days: 7

    - name: Run linting
      working-directory: ./services
      run: |
        echo "=== Running linting ==="
        # Install linting tools if not already installed
        pip install flake8 black
        # Run linting through build script
        ./build.sh --test-only common  # This includes linting

    # - name: Run tests with coverage
    #   working-directory: ./docker
    #   run: |
    #     python -m pytest tests -v --cov=api --cov-report=xml --cov-report=term

    # - name: Upload coverage reports
    #   uses: codecov/codecov-action@v3
    #   with:
    #     file: ./docker/coverage.xml
    #     flags: unittests
    #     name: codecov-umbrella

  # Job 2: Build Docker Image
  # build:
  #   name: Build Docker Image
  #   runs-on: ubuntu-latest
  #   needs: test
  #   if: github.event_name == 'push'

  #   steps:
  #   - name: Checkout code
  #     uses: actions/checkout@v4

  #   - name: Set up Docker Buildx
  #     uses: docker/setup-buildx-action@v3

  #   - name: Build Docker image
  #     working-directory: ./docker
  #     run: |
  #       # Corrected: Removed LaTeX formatting
  #       docker build -t ${{ env.ECR_REPOSITORY }}:${{ github.sha }} -f api/Dockerfile .
  #       docker tag ${{ env.ECR_REPOSITORY }}:${{ github.sha }} ${{ env.ECR_REPOSITORY }}:latest

  #   - name: Save Docker image
  #     run: |
  #       # Corrected: Removed LaTeX formatting
  #       docker save ${{ env.ECR_REPOSITORY }}:${{ github.sha }} > order-api.tar

  #   - name: Upload Docker image as artifact
  #     uses: actions/upload-artifact@v4
  #     with:
  #       name: docker-image
  #       path: order-api.tar
  #       retention-days: 1

  # Job 2-1 (New Job): Create Lambda deployment packages
  # package_lambdas:
  #   name: Create Lambda deployment packages
  #   runs-on: ubuntu-latest
  #   needs: test # Ensure tests pass before packaging
  #   if: github.event_name == 'push' # Only package on push (main or develop)

  #   steps:
  #   - name: Checkout code
  #     uses: actions/checkout@v4

  #   - name: Create dummy Lambda deployment packages
  #     # The working-directory is the root of your repository.
  #     # The script will navigate into and work within the 'services' directory.
  #     working-directory: .
  #     run: |
        # # Ensure the 'services' directory exists relative to the repo root
        # # mkdir -p services

        # # Change into the services directory. All subsequent commands in this block
        # # will operate relative to 'services/'.
        # cd services

        # # Define a temporary file name within the 'services' directory
        # TEMP_FILE="temp_dummy_lambda.py"

        # # Create the dummy Python file directly in the 'services' directory
        # echo 'def lambda_handler(event, context): import os; print(f"Lambda executed in {os.getcwd()}"); return {"statusCode": 200, "body": "Dummy Lambda executed"}' > "${TEMP_FILE}"

        # # Loop through the names of your Lambda functions and create their zip files
        # for name in order_processor inventory_manager notification_handler; do
        #   # Copy the temporary dummy file to the specific lambda's Python file name
        #   # (e.g., 'order_processor.py') within the 'services' directory.
        #   cp "${TEMP_FILE}" "${name}.py"

        #   # Create the zip file for each Lambda. The -j flag ensures only the file
        #   # itself is zipped, not its parent directory (services/).
        #   zip -j "${name}.zip" "${name}.py"
        #   echo "Created ${name}.zip"
        # done

    #     # Clean up all Python files (including the temporary dummy file and the copied ones)
    #     # from the 'services' directory.
    #     rm *.py

    # - name: Upload Lambda packages as artifact
    #   uses: actions/upload-artifact@v4
    #   with:
    #     name: lambda-packages
    #     path: services/*.zip # Upload all generated zip files
    #     retention-days: 1


  # # Job 3: Deploy AWS Infrastructure (Terraform) (only on main branch)
  # deploy: # This job name remains 'deploy'
  #   name: Deploy AWS Infrastructure
  #   runs-on: ubuntu-latest
  #   needs: [build, package_lambdas]
  #   if: github.ref == 'refs/heads/main' && github.event_name == 'push' # Only deploy infra on push to main

  #   steps:
  #   - name: Checkout code
  #     uses: actions/checkout@v4

  #   - name: Configure AWS credentials
  #     uses: aws-actions/configure-aws-credentials@v4
  #     with:
  #       aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
  #       aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  #       aws-region: ${{ env.AWS_REGION }}

  #   - name: Setup Terraform
  #     uses: hashicorp/setup-terraform@v3
  #     with:
  #       terraform_version: 1.5.0
  #       terraform_wrapper: false

  #   - name: Terraform Init
  #     id: init
  #     run: terraform init
  #     working-directory: ./terraform

  #   - name: Terraform Validate
  #     id: validate
  #     run: terraform validate
  #     working-directory: ./terraform

  #   - name: Terraform Plan
  #     id: plan
  #     run: terraform plan -no-color
  #     working-directory: ./terraform
  #     # Optionally, you can save the plan to an artifact if you want to review it later
  #     # run: terraform plan -out=tfplan.out

  #   - name: Terraform Apply
  #     id: apply
  #     if: steps.plan.outcome == 'success'
  #     run: terraform apply -auto-approve
  #     working-directory: ./terraform

  # # Job 4: Deploy to AWS (Push Docker Image & EKS Update)
  # deploy_application: # Renamed from 'deploy' to 'deploy_application' for clarity
  #   name: Push Image & Deploy Application
  #   runs-on: ubuntu-latest
  #   needs: deploy # CORRECTED: Now correctly depends on the 'deploy' job
  #   if: github.ref == 'refs/heads/main' && github.event_name == 'push'

  #   steps:
  #   - name: Checkout code
  #     uses: actions/checkout@v4

  #   - name: Configure AWS credentials
  #     uses: aws-actions/configure-aws-credentials@v4
  #     with:
  #       aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
  #       aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  #       aws-region: ${{ env.AWS_REGION }}

  #   - name: Login to Amazon ECR
  #     id: login-ecr
  #     uses: aws-actions/amazon-ecr-login@v2

  #   - name: Download Docker image artifact
  #     uses: actions/download-artifact@v4
  #     with:
  #       name: docker-image

  #   - name: Load and push Docker image to ECR
  #     env:
  #       ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
  #     run: |
  #       docker load < order-api.tar
  #       # Tag with the correct ECR URI, using the full repository name from Terraform
  #       # If your Terraform defines `order-processor-api` as the repo name
  #       ECR_REPO_NAME="order-processor-api" # Adjust this to your actual ECR repo name from Terraform
  #       docker tag ${{ env.ECR_REPOSITORY }}:${{ github.sha }} $ECR_REGISTRY/$ECR_REPO_NAME:${{ github.sha }}
  #       docker tag ${{ env.ECR_REPOSITORY }}:${{ github.sha }} $ECR_REGISTRY/$ECR_REPO_NAME:latest
  #       docker push $ECR_REGISTRY/$ECR_REPO_NAME:${{ github.sha }}
  #       docker push $ECR_REGISTRY/$ECR_REPO_NAME:latest

  #   - name: Update EKS deployment
  #     # This step should be uncommented and configured once you set up EKS.
  #     run: |
  #       echo "EKS deployment steps are commented out. Uncomment and configure when ready."
  #       # # Install kubectl
  #       # # curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
  #       # # chmod +x kubectl
  #       # # sudo mv kubectl /usr/local/bin/
  #       #
  #       # # Update kubeconfig
  #       # # aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name order-processor-cluster
  #       #
  #       # # Update deployment with new image
  #       # # Make sure 'order-api' matches your Kubernetes Deployment name and container name
  #       # # kubectl set image deployment/order-api order-api=$ECR_REGISTRY/$ECR_REPO_NAME:${{ github.sha }} -n default
  #       #
  #       # # Wait for rollout to complete
  #       # # kubectl rollout status deployment/order-api -n default

  # # Job 5: Run Integration Tests (Dummy)
  # integration_tests:
  #   name: Run Integration Tests
  #   runs-on: ubuntu-latest
  #   needs: [deploy, deploy_application]
  #   if: github.ref == 'refs/heads/main' && github.event_name == 'push'

  #   steps:
  #   - name: Checkout code
  #     uses: actions/checkout@v4

  #   - name: Set up Python
  #     uses: actions/setup-python@v4
  #     with:
  #       python-version: ${{ env.PYTHON_VERSION }}

  #   - name: Dummy Integration Tests
  #     env:
  #       API_URL: ${{ needs.deploy.outputs.api_gateway_url }}
  #       FRONTEND_URL: ${{ needs.deploy.outputs.frontend_url }}
  #     run: |
  #       echo "=== Running Dummy Integration Tests ==="
  #       echo "API URL: $API_URL"
  #       echo "Frontend URL: $FRONTEND_URL"

  #       # Dummy test 1
  #       echo "Test 1: Checking API connectivity..."
  #       sleep 2
  #       echo "✓ API connectivity test passed"

  #       # Dummy test 2
  #       echo "Test 2: Testing order creation endpoint..."
  #       sleep 2
  #       echo "✓ Order creation test passed"

  #       # Dummy test 3
  #       echo "Test 3: Testing inventory check..."
  #       sleep 2
  #       echo "✓ Inventory check test passed"

  #       echo "=== All integration tests passed! ==="

  # # Job 6: Destroy Infrastructure
  # destroy_infrastructure:
    # name: Destroy Infrastructure
    # runs-on: ubuntu-latest
    # needs: integration_tests
    # if: always() && github.ref == 'refs/heads/main' && github.event_name == 'push'

    # steps:
    # - name: Checkout code
    #   uses: actions/checkout@v4

    # - name: Configure AWS credentials
    #   uses: aws-actions/configure-aws-credentials@v4
    #   with:
    #     aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
    #     aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    #     aws-region: ${{ env.AWS_REGION }}

    # - name: Setup Terraform
    #   uses: hashicorp/setup-terraform@v3
    #   with:
    #     terraform_version: 1.5.0

    # - name: Terraform Init
    #   working-directory: ./terraform
    #   run: terraform init

    # - name: Pre-destroy Cleanup
    #   working-directory: ./terraform
    #   run: |
    #     echo "=== Starting pre-destroy cleanup ==="

    #     # Empty S3 buckets if they exist
    #     echo "Checking for S3 buckets to empty..."

    #     # Get all S3 buckets created by this Terraform
    #     BUCKETS=$(aws s3api list-buckets --query "Buckets[?contains(Name, 'order-processor') || contains(Name, 'cloud-native')].Name" --output text || true)

    #     if [ ! -z "$BUCKETS" ]; then
    #       for bucket in $BUCKETS; do
    #         echo "Emptying bucket: $bucket"
    #         aws s3 rm s3://$bucket --recursive || true

    #         # Also remove versioned objects if versioning is enabled
    #         aws s3api list-object-versions --bucket "$bucket" --output json | \
    #         jq -r '.Versions[]? | "\(.Key) \(.VersionId)"' | \
    #         while read key version; do
    #           if [ ! -z "$key" ] && [ ! -z "$version" ]; then
    #             aws s3api delete-object --bucket "$bucket" --key "$key" --version-id "$version" || true
    #           fi
    #         done 2>/dev/null || true
    #       done
    #     fi

    #     echo "=== Pre-destroy cleanup completed ==="

    # - name: Terraform Destroy
    #   working-directory: ./terraform
    #   run: |
    #     echo "=== Starting Terraform destroy ==="

    #     # Attempt to destroy with auto-approve
    #     terraform destroy -auto-approve || {
    #       echo "First destroy attempt failed, checking for stuck resources..."

    #       # List current state
    #       echo "Current Terraform state:"
    #       terraform state list || true

    #       # Common problematic resources - remove from state if destroy fails
    #       PROBLEM_RESOURCES="aws_s3_bucket aws_db_instance aws_msk_cluster"

    #       for resource_type in $PROBLEM_RESOURCES; do
    #         echo "Checking for $resource_type in state..."
    #         terraform state list | grep "^${resource_type}\." | while read resource; do
    #           echo "Removing $resource from state"
    #           terraform state rm "$resource" || true
    #         done
    #       done

    #       # Try destroy again
    #       echo "Retrying destroy after state cleanup..."
    #       terraform destroy -auto-approve || {
    #         echo "WARNING: Destroy failed again. Manual cleanup may be required."
    #         echo "Remaining resources in state:"
    #         terraform state list || true
    #       }
    #     }

    #     echo "=== Terraform destroy completed ==="

    # - name: Verify Cleanup
    #   if: always()
    #   run: |
    #     echo "=== Verifying resource cleanup ==="

    #     # Check for remaining RDS instances
    #     echo "Checking for RDS instances..."
    #     REMAINING_RDS=$(aws rds describe-db-instances --query "DBInstances[?contains(DBInstanceIdentifier, 'order-processor')].DBInstanceIdentifier" --output text || true)
    #     if [ ! -z "$REMAINING_RDS" ]; then
    #       echo "WARNING: RDS instances still exist: $REMAINING_RDS"
    #     else
    #       echo "✓ No RDS instances found"
    #     fi

    #     # Check for remaining Lambda functions
    #     echo "Checking for Lambda functions..."
    #     REMAINING_LAMBDA=$(aws lambda list-functions --query "Functions[?contains(FunctionName, 'order-processor')].FunctionName" --output text || true)
    #     if [ ! -z "$REMAINING_LAMBDA" ]; then
    #       echo "WARNING: Lambda functions still exist: $REMAINING_LAMBDA"
    #     else
    #       echo "✓ No Lambda functions found"
    #     fi

    #     # Check for remaining S3 buckets
    #     echo "Checking for S3 buckets..."
    #     REMAINING_S3=$(aws s3api list-buckets --query "Buckets[?contains(Name, 'order-processor') || contains(Name, 'cloud-native')].Name" --output text || true)
    #     if [ ! -z "$REMAINING_S3" ]; then
    #       echo "WARNING: S3 buckets still exist: $REMAINING_S3"
    #     else
    #       echo "✓ No S3 buckets found"
    #     fi

    #     echo "=== Cleanup verification completed ==="

    # - name: Cost Report
    #   if: always()
    #   run: |
    #     echo "=== Generating cost report ==="

    #     # Get today's date
    #     END_DATE=$(date +%Y-%m-%d)
    #     START_DATE=$(date -d '1 day ago' +%Y-%m-%d)

    #     # Try to get cost data
    #     echo "Estimated costs for this pipeline run:"
    #     aws ce get-cost-and-usage \
    #       --time-period Start=$START_DATE,End=$END_DATE \
    #       --granularity DAILY \
    #       --metrics "BlendedCost" \
    #       --group-by Type=DIMENSION,Key=SERVICE \
    #       --query 'ResultsByTime[0].Groups[?Metrics.BlendedCost.Amount > `0`].[Keys[0], Metrics.BlendedCost.Amount]' \
    #       --output table 2>/dev/null || echo "Cost data not available yet"

    #     echo "=== Cost report completed ==="